# Dispatch API

## Introduction

The Dispatch API is used in LiteRT for NPU acceleration. It works with the
[Compiler Plugin](COMPILER_PLUGIN.md) to execute Executable Binary Blob,
generated by the plugin.

## How Do Dispatch API Work?

Dispatch API is used by CompiledModel via the NpuAccelerator. This internally
creates a DispatchDelegate and it is this DispatchDelegate that uses the
Dispatch API to engage the NPU embedded in the currently running hardware.

## Dispatch API Data Types

In the Dispatch API, the following data types are used to execute a model on
NPUs.

- DispatchDeviceContext

  It is used to manage buffers to used by NPU inference.

- DispatchInvocationContext

  This is the data structure used to execute the model. It works by associating
  the actual input and output memory registered in DispatchDeviceContext with
  the generated DispatchGraph.

## Dispatch APIs

The full Dispatch APIs are defined in [vendors/c/litert_dispatch.h](./vendors/c/litert_dispatch.h) file.

This section shows basic Dispatch APIs.

### Initialization

```
LiteRtStatus LiteRtDispatchInitialize(
    LiteRtEnvironmentOptions environment_options, LiteRtOptions options);
```

### DispatchDeviceContext APIs

These APIs are used to create / delete DispatchDeviceContext objects, and
register TensorBuffers.

```
LiteRtStatus
LiteRtDispatchDeviceContextCreate(LiteRtDispatchDeviceContext* device_context);

LiteRtStatus
LiteRtDispatchDeviceContextDestroy(LiteRtDispatchDeviceContext device_context);

 LiteRtStatus LiteRtDispatchRegisterTensorBuffer(
    LiteRtDispatchDeviceContext device_context,
    LiteRtTensorBuffer tensor_buffer,
    LiteRtTensorBufferHandle* tensor_buffer_handle);

LiteRtStatus LiteRtDispatchUnregisterTensorBuffer(
    LiteRtDispatchDeviceContext device_context,
    LiteRtTensorBufferHandle tensor_buffer_handle);
```

### DispatchInvocationContext APIs

These APIs are used to create / modify / delete DispatchInvocationContext
objects. And finally invoke the associated Dispatch Executable.

```
LITERT_CAPI_EXPORT LiteRtStatus LiteRtDispatchInvocationContextCreate(
    LiteRtDispatchDeviceContext device_context,
    LiteRtDispatchExecutableType exec_type,
    const LiteRtMemBuffer* exec_bytecode_buffer, const char* function_name,
    int num_inputs, int num_outputs,
    LiteRtDispatchInvocationContext* invocation_context);

LITERT_CAPI_EXPORT LiteRtStatus LiteRtDispatchInvocationContextDestroy(
    LiteRtDispatchInvocationContext invocation_context);

LITERT_CAPI_EXPORT LiteRtStatus LiteRtDispatchAttachInput(
    LiteRtDispatchInvocationContext invocation_context, int graph_input_index,
    LiteRtTensorBufferHandle tensor_buffer_handle);

LITERT_CAPI_EXPORT LiteRtStatus LiteRtDispatchAttachOutput(
    LiteRtDispatchInvocationContext invocation_context, int graph_output_index,
    LiteRtTensorBufferHandle tensor_buffer_handle);

LITERT_CAPI_EXPORT LiteRtStatus
LiteRtDispatchInvoke(LiteRtDispatchInvocationContext invocation_context);
```

## An example NPU inference with Dispatch API

As stated previously, you won't need to use the Dispatch API directly since it's
called via the DispatchDelegate. The following example, however, helps
illustrate how it operates.

```

  LITERT_ASSERT_OK_AND_ASSIGN(auto env, CreateDefaultEnvironment());
  LITERT_ASSERT_OK_AND_ASSIGN(auto env_options, env.GetOptions());
  LITERT_ASSERT_OK_AND_ASSIGN(auto options, ::litert::Options::Create());

  ASSERT_EQ(LiteRtDispatchInitialize(env_options.Get(), options.Get()),
            kLiteRtStatusOk);

  const char* vendor_id;
  EXPECT_EQ(LiteRtDispatchGetVendorId(&vendor_id), kLiteRtStatusOk);
  ABSL_LOG(INFO) << "vendor_id: " << vendor_id;

  const char* build_id;
  EXPECT_EQ(LiteRtDispatchGetBuildId(&build_id), kLiteRtStatusOk);
  ABSL_LOG(INFO) << "build_id: " << build_id;

  LiteRtApiVersion api_version;
  EXPECT_EQ(LiteRtDispatchGetApiVersion(&api_version), kLiteRtStatusOk);
  ABSL_LOG(INFO) << "api_version: " << api_version.major << "."
                 << api_version.minor << "." << api_version.patch;

  int capabilities;
  EXPECT_EQ(LiteRtDispatchGetCapabilities(&capabilities), kLiteRtStatusOk);
  ABSL_LOG(INFO) << "capabilities: " << capabilities;

  LiteRtDispatchDeviceContext device_context = nullptr;
  EXPECT_EQ(LiteRtDispatchDeviceContextCreate(&device_context),
            kLiteRtStatusOk);
  ABSL_LOG(INFO) << "device_context: " << device_context;

  auto model_file_name =
      litert::testing::GetTestFilePath(kGoogleTensorModelFileName);
  auto model = litert::internal::LoadBinaryFile(model_file_name);
  EXPECT_TRUE(model) << model.Error();
  ABSL_LOG(INFO) << "Loaded model " << model_file_name << ", " << model->Size()
                 << " bytes";

  // ///////////////////////////////////////////////////////////////////////////
  // Set up an invocation context for a given model.
  // ///////////////////////////////////////////////////////////////////////////

  LiteRtMemBuffer exec_bytecode_buffer = {/*.fd=*/-1,
                                          /*.base_addr=*/model->Data(),
                                          /*.offset=*/0,
                                          /*.size=*/model->Size()};
  LiteRtDispatchInvocationContext invocation_context = nullptr;
  EXPECT_EQ(LiteRtDispatchInvocationContextCreate(
                device_context, kLiteRtDispatchExecutableTypeMlModel,
                &exec_bytecode_buffer, /*function_name=*/nullptr,
                /*num_inputs=*/2, /*num_outputs=*/1, &invocation_context),
            kLiteRtStatusOk);
  ABSL_LOG(INFO) << "Invocation context: " << invocation_context;

  // ///////////////////////////////////////////////////////////////////////////
  // Determine tensor buffer requirements.
  // ///////////////////////////////////////////////////////////////////////////

  int num_tensor_buffer_types;
  LiteRtTensorBufferRequirements input_0_tensor_buffer_requirements;
  EXPECT_EQ(LiteRtDispatchGetInputRequirements(
                invocation_context, /*input_index=*/0, &kInput0TensorType,
                &input_0_tensor_buffer_requirements),
            kLiteRtStatusOk);
  EXPECT_EQ(LiteRtGetNumTensorBufferRequirementsSupportedBufferTypes(
                input_0_tensor_buffer_requirements, &num_tensor_buffer_types),
            kLiteRtStatusOk);
  EXPECT_GE(num_tensor_buffer_types, 1);
  LiteRtTensorBufferType input_0_tensor_buffer_type;
  EXPECT_EQ(LiteRtGetTensorBufferRequirementsSupportedTensorBufferType(
                input_0_tensor_buffer_requirements, /*type_index=*/0,
                &input_0_tensor_buffer_type),
            kLiteRtStatusOk);
  EXPECT_EQ(input_0_tensor_buffer_type, kLiteRtTensorBufferTypeAhwb);
  size_t input_0_tensor_buffer_size;
  EXPECT_EQ(
      LiteRtGetTensorBufferRequirementsBufferSize(
          input_0_tensor_buffer_requirements, &input_0_tensor_buffer_size),
      kLiteRtStatusOk);
  EXPECT_GE(input_0_tensor_buffer_size, sizeof(kTestInput0Tensor));

  LiteRtTensorBufferRequirements input_1_tensor_buffer_requirements;
  EXPECT_EQ(LiteRtDispatchGetInputRequirements(
                invocation_context, /*input_index=*/1, &kInput1TensorType,
                &input_1_tensor_buffer_requirements),
            kLiteRtStatusOk);
  EXPECT_EQ(LiteRtGetNumTensorBufferRequirementsSupportedBufferTypes(
                input_1_tensor_buffer_requirements, &num_tensor_buffer_types),
            kLiteRtStatusOk);
  EXPECT_GE(num_tensor_buffer_types, 1);
  LiteRtTensorBufferType input_1_tensor_buffer_type;
  EXPECT_EQ(LiteRtGetTensorBufferRequirementsSupportedTensorBufferType(
                input_1_tensor_buffer_requirements, /*type_index=*/0,
                &input_1_tensor_buffer_type),
            kLiteRtStatusOk);
  EXPECT_EQ(input_1_tensor_buffer_type, kLiteRtTensorBufferTypeAhwb);
  size_t input_1_tensor_buffer_size;
  EXPECT_EQ(
      LiteRtGetTensorBufferRequirementsBufferSize(
          input_1_tensor_buffer_requirements, &input_1_tensor_buffer_size),
      kLiteRtStatusOk);
  EXPECT_GE(input_1_tensor_buffer_size, sizeof(kTestInput1Tensor));

  LiteRtTensorBufferRequirements output_tensor_buffer_requirements;
  EXPECT_EQ(LiteRtDispatchGetOutputRequirements(
                invocation_context, /*output_index=*/0, &kOutputTensorType,
                &output_tensor_buffer_requirements),
            kLiteRtStatusOk);
  EXPECT_EQ(LiteRtGetNumTensorBufferRequirementsSupportedBufferTypes(
                output_tensor_buffer_requirements, &num_tensor_buffer_types),
            kLiteRtStatusOk);
  EXPECT_GE(num_tensor_buffer_types, 1);
  LiteRtTensorBufferType output_tensor_buffer_type;
  EXPECT_EQ(LiteRtGetTensorBufferRequirementsSupportedTensorBufferType(
                output_tensor_buffer_requirements, /*type_index=*/0,
                &output_tensor_buffer_type),
            kLiteRtStatusOk);
  EXPECT_EQ(output_tensor_buffer_type, kLiteRtTensorBufferTypeAhwb);
  size_t output_tensor_buffer_size;
  EXPECT_EQ(LiteRtGetTensorBufferRequirementsBufferSize(
                output_tensor_buffer_requirements, &output_tensor_buffer_size),
            kLiteRtStatusOk);
  EXPECT_GE(output_tensor_buffer_size, sizeof(kTestOutputTensor));

  // ///////////////////////////////////////////////////////////////////////////
  // Allocate tensor buffers.
  // ///////////////////////////////////////////////////////////////////////////

  LiteRtTensorBuffer input_0_tensor_buffer;
  LITERT_EXPECT_OK(LiteRtCreateManagedTensorBuffer(
      env.Get(), input_0_tensor_buffer_type, &kInput0TensorType,
      input_0_tensor_buffer_size, &input_0_tensor_buffer));

  LiteRtTensorBuffer input_1_tensor_buffer;
  LITERT_EXPECT_OK(LiteRtCreateManagedTensorBuffer(
      env.Get(), input_1_tensor_buffer_type, &kInput1TensorType,
      input_1_tensor_buffer_size, &input_1_tensor_buffer));

  LiteRtTensorBuffer output_tensor_buffer;
  LITERT_EXPECT_OK(LiteRtCreateManagedTensorBuffer(
      env.Get(), output_tensor_buffer_type, &kOutputTensorType,
      output_tensor_buffer_size, &output_tensor_buffer));

  // ///////////////////////////////////////////////////////////////////////////
  // Register tensor buffers.
  // ///////////////////////////////////////////////////////////////////////////

  LiteRtTensorBufferHandle input_1_handle;
  LITERT_EXPECT_OK(LiteRtDispatchRegisterTensorBuffer(
      device_context, input_1_tensor_buffer, &input_1_handle));

  LiteRtTensorBufferHandle input_0_handle;
  LITERT_EXPECT_OK(LiteRtDispatchRegisterTensorBuffer(
      device_context, input_0_tensor_buffer, &input_0_handle));

  LiteRtTensorBufferHandle output_handle;
  LITERT_EXPECT_OK(LiteRtDispatchRegisterTensorBuffer(
      device_context, output_tensor_buffer, &output_handle));

  // ///////////////////////////////////////////////////////////////////////////
  // Attach tensor buffers.
  // ///////////////////////////////////////////////////////////////////////////

  LITERT_EXPECT_OK(LiteRtDispatchAttachInput(invocation_context,
                                             /*graph_input_index=*/0,
                                             input_0_handle));
  LITERT_EXPECT_OK(LiteRtDispatchAttachInput(invocation_context,
                                             /*graph_input_index=*/1,
                                             input_1_handle));
  LITERT_EXPECT_OK(LiteRtDispatchAttachOutput(invocation_context,
                                              /*graph_output_index=*/0,
                                              output_handle));

  // ///////////////////////////////////////////////////////////////////////////
  // Fill the input buffers with data.
  // ///////////////////////////////////////////////////////////////////////////

  {
    ABSL_LOG(INFO) << "Filling inputs with data";
    void* host_mem_addr;

    ASSERT_EQ(LiteRtLockTensorBuffer(input_0_tensor_buffer, &host_mem_addr,
                                     kLiteRtTensorBufferLockModeWrite),
              kLiteRtStatusOk);
    std::memcpy(host_mem_addr, kTestInput0Tensor, sizeof(kTestInput0Tensor));
    ASSERT_EQ(LiteRtUnlockTensorBuffer(input_0_tensor_buffer), kLiteRtStatusOk);

    ASSERT_EQ(LiteRtLockTensorBuffer(input_1_tensor_buffer, &host_mem_addr,
                                     kLiteRtTensorBufferLockModeWrite),
              kLiteRtStatusOk);
    std::memcpy(host_mem_addr, kTestInput1Tensor, sizeof(kTestInput1Tensor));
    ASSERT_EQ(LiteRtUnlockTensorBuffer(input_1_tensor_buffer), kLiteRtStatusOk);
  }

  // ///////////////////////////////////////////////////////////////////////////
  // Execute model.
  // ///////////////////////////////////////////////////////////////////////////

  ABSL_LOG(INFO) << "Invoking execution...";
  EXPECT_EQ(LiteRtDispatchInvoke(invocation_context), kLiteRtStatusOk);

  // ///////////////////////////////////////////////////////////////////////////
  // Check output for correctness.
  // ///////////////////////////////////////////////////////////////////////////

  {
    ABSL_LOG(INFO) << "Checking output...";
    void* host_mem_addr;
    ASSERT_EQ(LiteRtLockTensorBuffer(output_tensor_buffer, &host_mem_addr,
                                     kLiteRtTensorBufferLockModeRead),
              kLiteRtStatusOk);
    auto output = absl::MakeSpan(static_cast<const float*>(host_mem_addr),
                                 kTestOutputSize);
    for (auto i = 0; i < kTestOutputSize; ++i) {
      ABSL_LOG(INFO) << output[i] << "\t" << kTestOutputTensor[i];
    }
    EXPECT_THAT(output, Pointwise(testing::FloatNear(1e-3), kTestOutputTensor));
    ASSERT_EQ(LiteRtUnlockTensorBuffer(output_tensor_buffer), kLiteRtStatusOk);
  }

  // ///////////////////////////////////////////////////////////////////////////
  // Clean up resources.
  // ///////////////////////////////////////////////////////////////////////////
  EXPECT_EQ(LiteRtDispatchDetachInput(invocation_context,
                                      /*graph_input_index=*/0, input_0_handle),
            kLiteRtStatusOk);
  EXPECT_EQ(LiteRtDispatchDetachInput(invocation_context,
                                      /*graph_input_index=*/1, input_1_handle),
            kLiteRtStatusOk);
  EXPECT_EQ(LiteRtDispatchDetachOutput(invocation_context,
                                       /*graph_output_index=*/0, output_handle),
            kLiteRtStatusOk);
  EXPECT_EQ(LiteRtDispatchUnregisterTensorBuffer(device_context, output_handle),
            kLiteRtStatusOk);
  EXPECT_EQ(
      LiteRtDispatchUnregisterTensorBuffer(device_context, input_1_handle),
      kLiteRtStatusOk);
  EXPECT_EQ(
      LiteRtDispatchUnregisterTensorBuffer(device_context, input_0_handle),
      kLiteRtStatusOk);
  LiteRtDestroyTensorBuffer(output_tensor_buffer);
  LiteRtDestroyTensorBuffer(input_1_tensor_buffer);
  LiteRtDestroyTensorBuffer(input_0_tensor_buffer);
  EXPECT_EQ(LiteRtDispatchInvocationContextDestroy(invocation_context),
            kLiteRtStatusOk);
  EXPECT_EQ(LiteRtDispatchDeviceContextDestroy(device_context),
            kLiteRtStatusOk);
```
