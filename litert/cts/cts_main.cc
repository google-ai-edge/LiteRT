// Copyright 2025 Google LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <array>
#include <cstddef>
#include <cstdint>
#include <memory>
#include <string>
#include <utility>
#include <vector>

#include <gtest/gtest.h>
#include "absl/flags/parse.h"  // from @com_google_absl
#include "absl/strings/str_format.h"  // from @com_google_absl
#include "absl/strings/string_view.h"  // from @com_google_absl
#include "litert/c/litert_common.h"
#include "litert/c/litert_logging.h"
#include "litert/c/litert_op_code.h"
#include "litert/cc/litert_buffer_ref.h"
#include "litert/cc/litert_c_types_printing.h"  // IWYU pragma: keep
#include "litert/cc/litert_detail.h"
#include "litert/cc/litert_element_type.h"
#include "litert/cc/litert_expected.h"
#include "litert/cc/litert_layout.h"
#include "litert/cc/litert_macros.h"
#include "litert/cc/litert_rng.h"
#include "litert/core/model/model.h"
#include "litert/core/model/model_load.h"
#include "litert/core/model/model_serialize.h"
#include "litert/core/util/flatbuffer_tools.h"
#include "litert/test/generators/common.h"
#include "litert/test/rng_fixture.h"
#include "tflite/schema/schema_generated.h"

namespace litert {
namespace testing {
namespace {

using ::litert::internal::AttachInput;
using ::litert::internal::AttachOutput;
using ::litert::internal::LoadModelFromBuffer;
using ::litert::internal::SerializeModel;
using ::litert::internal::SetTflOpCodes;
using ::litert::internal::TflOpCode;
using ::litert::internal::TflOpCodePtr;
using ::litert::internal::TflOptions;
using ::testing::RegisterTest;

// EXAMPLE TEST LOGIC //////////////////////////////////////////////////////////

// Reference cts test logic implementation that does simply returns the input.
// Used as an example and to sanity check the framework.
//
// Note: Template parameters for all test logics define the axis of
// configurability on which we want to explicitly *enumerate* values for
// (rather than randomly generate them). This is appropriate for paramters
// where the space of possible values is small and known (e.g. types, ranks).
//    In order to work with the combinatorial parameter expand/specialize
// utilities, the template params cannot not be non-type, but these can
// be simulated simply with a standard std::integral_constant.
template <typename Rank, typename T>
struct NoOp {
 private:
  // Used by by random tensor shape generator to cap the size of the tensor.
  static constexpr size_t kMaxTensorSize = 1024;

  static_assert(std::is_same_v<typename Rank::value_type, size_t>);
  // Rank of the input and output tensor.
  static constexpr size_t kRank = Rank::value;

  // Names of the input and output tensor.
  static constexpr TensorNames<2> kInputNames = {"input"};
  static constexpr TensorNames<2> kOutputNames = {"output"};

  // Signature name of the model.
  static constexpr absl::string_view kSignatureName = "default";

  // Litert element type enum taken from c++ type T.
  static constexpr ElementType kElementType = GetElementType<T>();

  // The compliment of the "enumerated" template parameters. A "params"
  // typed is defined by all test logics and encapsulates all of the paramters
  // of this test that are randomly generated. This is suitable for larger
  // and practically unbounded spaces (like shapes).
  struct Params {
    std::array<Layout::Dim, kRank> shape;
  };

  // Utility for mapping litert ops to corresponding tflite schema types.
  using FbTypes = FbOpTypes<kLiteRtOpCodeTflAdd>;

 public:
  // Defines consituent types needed by the driver code. All test logics
  // must have one of these as a public member type.
  using Traits = TestLogicTraits<TypeList<T>, TypeList<T>, Params>;

  // A common name for all tests generated by this logic. This should
  // describe the non-random parameters (see template).
  static std::string Name() {
    const auto kName = absl::StrFormat("NoOp_Rank=%lu_T=%v", kRank,
                                       LiteRtElementType(kElementType));
    return kName;
  }

  // Given an instance of random params, construct the graph under test.
  Expected<LiteRtModelT::Ptr> BuildGraph(const Params& params) {
    LiteRtModelT model;
    std::vector<TflOpCodePtr> tfl_codes;

    auto& sg = model.EmplaceSubgraph();

    auto& tensor = sg.EmplaceTensor();
    {
      tensor.SetType(::MakeRankedTensorType(LiteRtElementType(kElementType),
                                            params.shape));
      tensor.SetName(std::string(kInputNames[0]));
      sg.Inputs().push_back(&tensor);
    }

    auto& cst = sg.EmplaceTensor();
    {
      cst.SetType(::MakeRankedTensorType(LiteRtElementType(kElementType), {}));
      cst.SetName("cst");
      const T cst_data = 0;
      BufferRef<uint8_t> cst_buffer(&cst_data, sizeof(T));
      ::SetWeightsFromUnownedBuffer(cst.Weights(), cst_buffer);
    }

    auto& output = sg.EmplaceTensor();
    {
      output.SetType(::MakeRankedTensorType(LiteRtElementType(kElementType),
                                            params.shape));
      output.SetName(std::string(kOutputNames[0]));
      sg.Outputs().push_back(&output);
    }

    auto& op = sg.EmplaceOp();
    {
      op.SetOpCode(kLiteRtOpCodeTflAdd);
      TflOptions opts;
      opts.type = FbTypes::kBuiltinOptions;
      typename FbTypes::OptionsT add_opts;
      add_opts.fused_activation_function =
          ::tflite::ActivationFunctionType_NONE;
      add_opts.pot_scale_int16 = false;
      opts.Set(std::move(add_opts));
      internal::SetTflOptions(op, std::move(opts));
      auto code = std::make_unique<TflOpCode>();
      code->builtin_code = FbTypes::kBuiltinOperator;
      code->version = 1;
      internal::SetTflOpCodeInd(op, tfl_codes.size());
      tfl_codes.push_back(std::move(code));
    }

    AttachInput(&tensor, op);
    AttachInput(&cst, op);
    AttachOutput(&output, op);

    std::vector<std::string> input_names = {std::string(kInputNames[0])};
    std::vector<std::string> output_names = {std::string(kOutputNames[0])};
    model.EmplaceSignature(&sg, std::move(input_names), std::move(output_names),
                           std::string(kSignatureName));

    SetTflOpCodes(model, std::move(tfl_codes));

    LITERT_ASSIGN_OR_RETURN(auto serialized, SerializeModel(std::move(model)));
    return LoadModelFromBuffer(std::move(serialized));
  }

  // Generate an instance of the random params for this test logic with the
  // given random device.
  template <typename Rng>
  Expected<Params> GenerateParams(Rng& rng) {
    RandomTensorType<kRank, kMaxTensorSize, LiteRtElementType(kElementType)>
        type;
    LITERT_ASSIGN_OR_RETURN(const auto tensor_type, type(rng));
    Params p;
    std::copy(std::cbegin(tensor_type.layout.dimensions),
              std::cbegin(tensor_type.layout.dimensions) + kRank,
              std::begin(p.shape));
    return p;
  }

  // Initialize input buffers with random data, these will be passed to the
  // compiled model api.
  template <typename Rng>
  Expected<typename Traits::InputBuffers> MakeInputs(Rng& rng,
                                                     const Params& params) {
    // TODO: Implement.
    return Error(kLiteRtStatusErrorUnsupported, "Not implemented");
  }

  // Initialize output buffers, these will be passed to the compiled model api.
  Expected<typename Traits::OutputBuffers> MakeOutputs(const Params& params) {
    // TODO: Implement.
    return Error(kLiteRtStatusErrorUnsupported, "Not implemented");
  }

  // Reference implementation which the driver code will compare the actual
  // results against.
  Expected<void> Reference(const Params& params,
                           const Traits::ReferenceInputs& inputs,
                           const Traits::ReferenceOutputs& outputs) {
    // TODO: Implement.
    return Error(kLiteRtStatusErrorUnsupported, "Not implemented");
  }
};

// DRIVER CODE /////////////////////////////////////////////////////////////////

// Class that drives all cts test cases. These are specialized with
// fully specified test logic and executor (backend).
template <typename TestLogic, typename TestExecutor = void>
class CtsTest : public RngTest {
 private:
  using Logic = TestLogic;
  using Executor = TestExecutor;

 public:
  // Register a fully specified case with gtest. This will generate an instance
  // of the random params needed to finish specifying the test logic and is
  // inteded to be called multiple times to generate coverage across the space
  // of possible random params.
  template <typename Rng>
  static Expected<void> Register(size_t iter, Rng& rng) {
    using TestClass = CtsTest<Logic, Executor>;

    const auto suite_name = TestLogic::Name();
    const auto iter_prefix = absl::StrFormat("iter=%lu", iter);
    LITERT_LOG(LITERT_INFO, "Starting registration for %s, %s",
               suite_name.c_str(), iter_prefix.c_str());

    Logic logic;

    LITERT_ASSIGN_OR_RETURN(auto params, logic.GenerateParams(rng));
    LITERT_LOG(LITERT_INFO, "Generated params.");

    LITERT_ASSIGN_OR_RETURN(auto model, logic.BuildGraph(params));
    LITERT_LOG(LITERT_INFO, "Built graph.");

    const auto test_name =
        absl::StrFormat("%s/%v", iter_prefix, model->Subgraph(0).Ops());

    RegisterTest(suite_name.data(), test_name.c_str(), nullptr, nullptr,
                 __FILE__, __LINE__,
                 [model = std::move(model), params = std::move(params),
                  logic = std::move(logic)]() mutable -> TestClass* {
                   return new TestClass(std::move(model), std::move(params),
                                        std::move(logic));
                 });

    return {};
  }

  // [WIP] Run compiled model with random inputs and compare against the
  // reference implementation.
  void TestBody() override {
    // TODO implement. Call reference and compiled model and compare results.
    GTEST_SKIP() << "Not implemented";
  }

 private:
  CtsTest(LiteRtModelT::Ptr model, Logic::Traits::Params params, Logic logic)
      : model_(std::move(model)), params_(std::move(params)) {}

  typename LiteRtModelT::Ptr model_;
  typename Logic::Traits::Params params_;
  Logic logic_;
};

// Utility to register a test logic a given number of times with a common
// random device.
class RegisterFunctor {
 public:
  template <typename Logic>
  void operator()() {
    for (size_t i = 0; i < iters_; ++i) {
      if (auto status = CtsTest<Logic>::Register(i, device_); !status) {
        LITERT_LOG(LITERT_WARNING, "Failed to register CTS test %s_%lu: %s",
                   Logic::Name().c_str(), i, status.Error().Message().c_str());
      }
    }
  }

  explicit RegisterFunctor(size_t iters) : iters_(iters) {}

 private:
  const size_t iters_;
  DefaultDevice device_;
};

// Specializes the given test logic template with the cartesian product of
// the given type lists and registers each specialization a given number
// of times. Each of these registrations will yield a single test case with a
// a different set of random parameters.
template <template <typename...> typename Logic, typename... Lists>
void RegisterCombinations(size_t iters) {
  RegisterFunctor f(iters);
  ExpandProduct<Logic, Lists...>(f);
}

}  // namespace

// Register all the cts tests.
void RegisterCtsTests() {
  {
    // NO OP //
    // clang-format off
    RegisterCombinations<
        NoOp,  // Test logic template
        SizeListC<1, 2, 3, 4>,  // Ranks
        TypeList<float, int32_t>  // Data types
    >(/*iters=*/10);
    // clang-format on
  }
}

}  // namespace testing
}  // namespace litert

int main(int argc, char** argv) {
  ::testing::InitGoogleTest(&argc, argv);
  absl::ParseCommandLine(argc, argv);
  litert::testing::RegisterCtsTests();
  return RUN_ALL_TESTS();
}
